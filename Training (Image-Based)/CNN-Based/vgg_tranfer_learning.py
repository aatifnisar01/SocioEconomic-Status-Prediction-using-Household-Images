# -*- coding: utf-8 -*-
"""census-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kA17cBBKD_ndhlL-uKr9r6KufBXdNohq
"""

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import numpy as np
import os
import PIL
import PIL.Image
import tensorflow as tf
import pathlib

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout
from tensorflow.keras.applications.vgg16 import preprocess_input
print(tf.__version__)

# !cp -r ./drive/My\ Drive/HouseInterior_old/ ./

import tensorflow as tf
#device_name = tf.test.gpu_device_name()
#if device_name != '/device:GPU:0':
#  raise SystemError('GPU device not found')
#print('Found GPU at: {}'.format(device_name))
#print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))
#tf.debugging.set_log_device_placement(True)

# data_dir = '../census/data/HouseInterior/'
#data_dir = 'C:/Users/Aatif/Downloads/archive/data'
#data_dir = pathlib.Path(data_dir)
#image_count = len(list(data_dir.glob('*/*.jpg')))

vgg_model = tf.keras.applications.VGG16(include_top=False, weights='imagenet', pooling='max', input_tensor=None, input_shape=(224,224,3))
model = Sequential()
model.add(vgg_model)
model.add(Dense(512))
model.add(Dropout(0.5))
model.add(Dense(128))
model.add(Dropout(0.2))
model.add(Dense(32))
model.add(Dense(5, activation='softmax'))

model.layers[0].trainable = False
for layer in model.layers[0].layers[-3:]:
  layer.trainable = True
model.summary()

batch_size = 32
img_height = 224
img_width = 224

data_dir1="C:/AHI data/Interior_Images/train"
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir1)

# =============================================================================
# train_ds = tf.keras.preprocessing.image_dataset_from_directory(
#   data_dir,
#   validation_split=0.33,
#   subset="training",
#   seed=42,
#   image_size=(img_height, img_width),
#   batch_size=batch_size)
# =============================================================================
data_dir2="C:/AHI data/Interior_Images/test"
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir2)

# =============================================================================
# val_ds = tf.keras.preprocessing.image_dataset_from_directory(
#   data_dir,
#   validation_split=0.33,
#   subset="validation",
#   seed=42,
#   image_size=(img_height, img_width),
#   batch_size=batch_size)
# =============================================================================

IMG_SIZE = 224
resize_and_rescale = tf.keras.Sequential([
  layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),
  layers.experimental.preprocessing.Rescaling(1./255)
])
normalized_ds = train_ds.map(lambda x, y: (resize_and_rescale(x), (y)))
normalized_val_ds = val_ds.map(lambda x, y: (resize_and_rescale(x), (y)))

AUTOTUNE = tf.data.experimental.AUTOTUNE

train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
normalized_ds = normalized_ds.cache().prefetch(buffer_size=-1)
normalized_val_ds = normalized_val_ds.cache().prefetch(buffer_size=-1)

opt = tf.keras.optimizers.Adamax(lr = 0.0004)
model.compile(optimizer='adamax', loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])

hisTory = model.fit(normalized_ds,
        epochs=20,
        validation_data=normalized_val_ds,
        batch_size=batch_size, use_multiprocessing=True)
print(hisTory.history)
# experiment 1:
# - Tried simple VGG16 architecture as transfer learning base model.
# - Used 2 Dense layers with dropout of 0.3 between them.
# - Till 20 epochs, val_accuracy were in acc to training acc, after that val_accuracy stuck around 0.276. lr was decreased in subsequent epochs but no improvement.
# - Take from this: K-Cross validation can be the final judge if this architecture is good or not.

import matplotlib.pyplot as plt

# Loss Curves
plt.figure(figsize=[8,6])
plt.plot(hisTory.history['loss'],'r',linewidth=3.0)
plt.plot(hisTory.history['val_loss'],'b',linewidth=3.0)
plt.legend(['Training loss', 'Validation Loss'],fontsize=18)
plt.xlabel('Epochs ',fontsize=16)
plt.ylabel('Loss',fontsize=16)
plt.title('Loss Curves',fontsize=16)

# Accuracy Curves
plt.figure(figsize=[8,6])
plt.plot(hisTory.history['accuracy'],'r',linewidth=3.0)
plt.plot(hisTory.history['val_accuracy'],'b',linewidth=3.0)
plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)
plt.xlabel('Epochs ',fontsize=16)
plt.ylabel('Accuracy',fontsize=16)
plt.title('Accuracy Curves',fontsize=16)